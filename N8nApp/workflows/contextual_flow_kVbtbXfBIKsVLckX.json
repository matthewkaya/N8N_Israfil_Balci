{
  "createdAt": "2025-05-12T16:34:47.135Z",
  "updatedAt": "2025-05-12T16:34:47.135Z",
  "id": "kVbtbXfBIKsVLckX",
  "name": "Contextual Flow",
  "active": false,
  "nodes": [
    {
      "parameters": {
        "model": "gpt-4.1-mini",
        "options": {}
      },
      "id": "9592ea40-0140-4f0c-9220-7364868222b3",
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1,
      "position": [
        640,
        140
      ]
    },
    {
      "parameters": {
        "jsonMode": "expressionData",
        "jsonData": "={{\n{\n  \"content\": `${ $json.text }\\n---\\n${ $json.chunk }`\n}\n}}",
        "options": {
          "metadata": {
            "metadataValues": [
              {
                "name": "=file_id",
                "value": "={{ $('Set File ID').first().json.file_id }}"
              },
              {
                "name": "file_title",
                "value": "={{ $('Set File ID').first().json.file_title }}"
              },
              {
                "name": "file_url",
                "value": "={{ $('Set File ID').first().json.file_url }}"
              }
            ]
          }
        }
      },
      "id": "f8f8b614-7578-4de0-8d97-39aa1abdea0e",
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "typeVersion": 1,
      "position": [
        3100,
        900
      ]
    },
    {
      "parameters": {
        "model": "text-embedding-3-small",
        "options": {}
      },
      "id": "45e73629-adf4-493f-be2c-a987854140d7",
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1,
      "position": [
        2920,
        900
      ]
    },
    {
      "parameters": {
        "content": "## Tool to Add Google Drive Files to Vector DB with Contextual Retrieval Augmentation",
        "height": 867,
        "width": 3053,
        "color": 5
      },
      "id": "9f307ec1-6a24-4e07-b017-42c24a061e58",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        360,
        340
      ]
    },
    {
      "parameters": {
        "operation": "download",
        "fileId": {
          "__rl": true,
          "value": "={{ $('Set File ID').item.json.file_id }}",
          "mode": "id"
        },
        "options": {
          "googleFileConversion": {
            "conversion": {
              "docsToFormat": "text/plain"
            }
          }
        }
      },
      "id": "1828b9f1-683d-4199-a102-4871e64f6650",
      "name": "Download File",
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        1500,
        460
      ],
      "executeOnce": true
    },
    {
      "parameters": {
        "pollTimes": {
          "item": [
            {
              "mode": "everyMinute"
            }
          ]
        },
        "triggerOn": "specificFolder",
        "folderToWatch": {
          "__rl": true,
          "value": "YOUR FOLDER ID",
          "mode": "list",
          "cachedResultName": "YOUR FOLDER NAME",
          "cachedResultUrl": "YOUR FOLDER URL"
        },
        "event": "fileCreated",
        "options": {}
      },
      "id": "7337345f-baa9-4255-96ff-3cfa88271169",
      "name": "File Created",
      "type": "n8n-nodes-base.googleDriveTrigger",
      "typeVersion": 1,
      "position": [
        420,
        460
      ]
    },
    {
      "parameters": {
        "pollTimes": {
          "item": [
            {
              "mode": "everyMinute"
            }
          ]
        },
        "triggerOn": "specificFolder",
        "folderToWatch": {
          "__rl": true,
          "value": "YOUR FOLDER ID",
          "mode": "list",
          "cachedResultName": "YOUR FOLDER NAME",
          "cachedResultUrl": "YOUR FOLDER URL"
        },
        "event": "fileUpdated",
        "options": {}
      },
      "id": "14b8bbe0-a947-4365-b514-9e7d5a27ceed",
      "name": "File Updated",
      "type": "n8n-nodes-base.googleDriveTrigger",
      "typeVersion": 1,
      "position": [
        420,
        620
      ]
    },
    {
      "parameters": {
        "operation": "text",
        "options": {}
      },
      "id": "97d4dabd-c2fa-4136-9f2a-c6c69aa00559",
      "name": "Extract Document Text",
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        1720,
        620
      ],
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "={{ $(\"When chat message received\").item.json.sessionId }}"
      },
      "id": "79bd8091-8ad3-445b-b526-79468a8567c6",
      "name": "Postgres Chat Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1,
      "position": [
        780,
        160
      ],
      "notesInFlow": false
    },
    {
      "parameters": {
        "operation": "delete",
        "tableId": "documents",
        "filterType": "string",
        "filterString": "=metadata->>file_id=like.*{{ $json.file_id }}*"
      },
      "id": "42c14da9-2e6f-4122-b810-6b8fd23dddfa",
      "name": "Delete Old Doc Rows",
      "type": "n8n-nodes-base.supabase",
      "typeVersion": 1,
      "position": [
        1040,
        460
      ],
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "10646eae-ae46-4327-a4dc-9987c2d76173",
              "name": "file_id",
              "value": "={{ $json.id }}",
              "type": "string"
            },
            {
              "id": "f4536df5-d0b1-4392-bf17-b8137fb31a44",
              "name": "file_type",
              "value": "={{ $json.mimeType }}",
              "type": "string"
            },
            {
              "id": "77d782de-169d-4a46-8a8e-a3831c04d90f",
              "name": "file_title",
              "value": "={{ $json.name }}",
              "type": "string"
            },
            {
              "id": "9bde4d7f-e4f3-4ebd-9338-dce1350f9eab",
              "name": "file_url",
              "value": "={{ $json.webViewLink }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "id": "bec1d01e-1beb-4b72-8d92-f02b0c5f5aef",
      "name": "Set File ID",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        820,
        600
      ]
    },
    {
      "parameters": {
        "content": "## Query Expansion + Agentic RAG AI Agent with Contextual Retrieval",
        "height": 485,
        "width": 1036
      },
      "id": "c4e222dc-aaf9-46e6-9e68-bcd52a49872d",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        360,
        -160
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.text }}",
        "options": {
          "systemMessage": "=## Role\n\nYou are a Retrieval-Augmented Generation (RAG) assistant designed to answer questions a user has. You use a corpus of documents that are all text based. Your primary goal is to provide accurate, up-to-date, and relevant information based on what the user asks and the documents you retrieve.\n\n## Responsibilities\n\n- Answer user queries with a good mix of being comprehensive but still concise\n- Retrieve and synthesize relevant information from the given tools to perform RAG in the 'documents' table, and look up the documents available in your knowledge base in the 'document_metadata' table\n- Present information in an easy-to-understand and professional manner  \n- Clarify misconceptions or misinformation\n\n## Other Key Information and Instructions\n\n- Always start by performing RAG. If RAG doesn't help, then look at the documents that are available to you, find a few that you think would contain the answer, and then analyze those.\n- Always tell the user if you didn't find the answer. Don't make something up just to please them.\n- Keep your language neutral and factual. Do not show bias or opinion  \n\n## Error Handling\n- If the information cannot be found using the provided instructions respond with:  \n  “I’m sorry, I couldn’t find relevant information based on your documents.”\n"
        }
      },
      "id": "600b3c2c-8224-41c4-806f-960bdfaba03a",
      "name": "RAG AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        920,
        -80
      ]
    },
    {
      "parameters": {
        "mode": "insert",
        "tableName": {
          "__rl": true,
          "value": "documents",
          "mode": "list",
          "cachedResultName": "documents"
        },
        "options": {
          "queryName": "match_documents"
        }
      },
      "id": "c2d0e118-eee4-4f37-a6d8-2a4632b6c852",
      "name": "Insert into Supabase Vectorstore",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "typeVersion": 1,
      "position": [
        3000,
        640
      ]
    },
    {
      "parameters": {
        "content": "## Run Each Node Once to Set Up Database Tables",
        "height": 480,
        "width": 1040,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        2180,
        -160
      ],
      "typeVersion": 1,
      "id": "4e03749d-f59b-4fbe-a32e-e72048557115",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "CREATE TABLE document_metadata (\n    id TEXT PRIMARY KEY,\n    title TEXT,\n    url TEXT,\n    created_at TIMESTAMP DEFAULT NOW(),\n    schema TEXT\n);",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        2640,
        40
      ],
      "id": "a18fb1c6-b545-48b2-b8e1-57504809d9e4",
      "name": "Create Document Metadata Table"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "CREATE TABLE document_rows (\n    id SERIAL PRIMARY KEY,\n    dataset_id TEXT REFERENCES document_metadata(id),\n    row_data JSONB  -- Store the actual row data\n);",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        2920,
        40
      ],
      "id": "a0cb82e1-f171-44f6-9afe-89f11e21f572",
      "name": "Create Document Rows Table (for Tabular Data)"
    },
    {
      "parameters": {
        "descriptionType": "manual",
        "toolDescription": "Use this tool to fetch all available documents, including the table schema if the file is a CSV or Excel file.",
        "operation": "select",
        "schema": {
          "__rl": true,
          "mode": "list",
          "value": "public"
        },
        "table": {
          "__rl": true,
          "value": "document_metadata",
          "mode": "list",
          "cachedResultName": "document_metadata"
        },
        "returnAll": true,
        "options": {}
      },
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.5,
      "position": [
        920,
        140
      ],
      "id": "8b1a621d-51b8-4dc8-9539-c85ebac0267c",
      "name": "List Documents"
    },
    {
      "parameters": {
        "descriptionType": "manual",
        "toolDescription": "Given a file ID, fetches the text from the document.",
        "operation": "executeQuery",
        "query": "SELECT \n    string_agg(content, ' ') as document_text\nFROM documents\n  WHERE metadata->>'file_id' = $1\nGROUP BY metadata->>'file_id';",
        "options": {
          "queryReplacement": "={{ $fromAI('file_id') }}"
        }
      },
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.5,
      "position": [
        1060,
        160
      ],
      "id": "b6381959-b887-4591-821d-cfefe8d99429",
      "name": "Get File Contents"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        1220,
        180
      ],
      "id": "14bb60cc-35bf-41dc-ae7e-c70f8374983e",
      "name": "Embeddings OpenAI2"
    },
    {
      "parameters": {
        "options": {
          "reset": false
        }
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        640,
        460
      ],
      "id": "949277cd-8167-4219-8fc7-4908416327e9",
      "name": "Loop Over Items"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- Enable the pgvector extension to work with embedding vectors\ncreate extension vector;\n\n-- Create a table to store your documents\ncreate table documents (\n  id bigserial primary key,\n  content text, -- corresponds to Document.pageContent\n  metadata jsonb, -- corresponds to Document.metadata\n  embedding vector(1536) -- 1536 works for OpenAI embeddings, change if needed\n);\n\n-- Create a function to search for documents\ncreate function match_documents (\n  query_embedding vector(1536),\n  match_count int default null,\n  filter jsonb DEFAULT '{}'\n) returns table (\n  id bigint,\n  content text,\n  metadata jsonb,\n  similarity float\n)\nlanguage plpgsql\nas $$\n#variable_conflict use_column\nbegin\n  return query\n  select\n    id,\n    content,\n    metadata,\n    1 - (documents.embedding <=> query_embedding) as similarity\n  from documents\n  where metadata @> filter\n  order by documents.embedding <=> query_embedding\n  limit match_count;\nend;\n$$;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        2340,
        40
      ],
      "id": "20981187-4e2a-408c-aff6-db8dace194ec",
      "name": "Create Documents Table and Match Function"
    },
    {
      "parameters": {
        "operation": "upsert",
        "schema": {
          "__rl": true,
          "mode": "list",
          "value": "public"
        },
        "table": {
          "__rl": true,
          "value": "document_metadata",
          "mode": "list",
          "cachedResultName": "document_metadata"
        },
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "id": "={{ $('Set File ID').item.json.file_id }}",
            "title": "={{ $('Set File ID').item.json.file_title }}",
            "url": "={{ $('Set File ID').item.json.file_url }}"
          },
          "matchingColumns": [
            "id"
          ],
          "schema": [
            {
              "id": "id",
              "displayName": "id",
              "required": true,
              "defaultMatch": true,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            },
            {
              "id": "title",
              "displayName": "title",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": false
            },
            {
              "id": "url",
              "displayName": "url",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": false,
              "removed": false
            },
            {
              "id": "created_at",
              "displayName": "created_at",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "dateTime",
              "canBeUsedToMatch": false
            },
            {
              "id": "schema",
              "displayName": "schema",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": false,
              "removed": true
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [
        1280,
        600
      ],
      "id": "daa19746-a98a-4e86-b163-170e05950a3b",
      "name": "Insert Document Metadata",
      "executeOnce": true
    },
    {
      "parameters": {
        "chunkSize": 2000,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "typeVersion": 1,
      "position": [
        3200,
        1040
      ],
      "id": "71be7d8e-bf62-41a0-bfa2-0d620fdf33a6",
      "name": "Recursive Character Text Splitter"
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolName": "documents",
        "toolDescription": "Use RAG to look up information in the knowledgebase.",
        "tableName": {
          "__rl": true,
          "value": "documents",
          "mode": "list",
          "cachedResultName": "documents"
        },
        "options": {
          "queryName": "match_documents"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "typeVersion": 1,
      "position": [
        1120,
        60
      ],
      "id": "cedb7d52-c306-4aad-83a9-5ea9dd1c1afd",
      "name": "Document RAG Tool"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        460,
        160
      ],
      "id": "a30009c8-386b-44b1-a8e4-660ab914ccab",
      "name": "OpenAI Chat Model1"
    },
    {
      "parameters": {
        "messages": {
          "messageValues": [
            {
              "message": "=## Context\nYou are a standalone Query Expansion AI Agent. You operate as the first step in a Retrieval‑Augmented Generation (RAG) system designed to answer questions. Your role is to take user queries and expand or rephrase them to make them more complete, specific, and information‑rich, so the downstream RAG agent can retrieve the most relevant data from its knowledge base.\n\n## Role\nYou do not access any external tools, databases, or documents. You do not provide answers. Your sole responsibility is to enhance the user’s query in a way that makes the user’s intent clearer and easier to process by the next stage of the system.\n\n## Responsibilities and Goals\n- Clarify vague or brief user queries\n- Add relevant context, terminology, and implied meaning  \n- Rephrase the query into a more specific and structured form while preserving the user’s intent  \n- Ensure the output remains a natural, information‑seeking query suitable for retrieval\n\n## Strict Boundaries and Rules\n- Only ever output a question (versus an answer)\n- Only output a single expanded query  \n\n## Final Notes\n- Your output will be passed directly to a retrieval system  \n- Ensure clarity, specificity, and neutrality  \n- Keep the output natural, readable, and focused on improving retrieval accuracy  "
            },
            {
              "message": "="
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.6,
      "position": [
        580,
        -80
      ],
      "id": "6ce1af59-dd14-40bc-bfdf-f2aa8534b368",
      "name": "Query Expansion"
    },
    {
      "parameters": {
        "model": "gpt-4.1-mini",
        "options": {}
      },
      "id": "b40f8125-a30b-4610-be54-363903fc3b20",
      "name": "OpenAI Chat Model2",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1,
      "position": [
        1520,
        160
      ]
    },
    {
      "parameters": {},
      "id": "6a0befcd-5fa2-4563-bc3e-1fada1b4aeaa",
      "name": "Postgres Chat Memory1",
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1,
      "position": [
        1680,
        140
      ],
      "notesInFlow": false
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chatInput }}",
        "options": {
          "systemMessage": "## Role\n\nYou are a Retrieval-Augmented Generation (RAG) assistant designed to answer questions a user has. You use a corpus of documents that are all text based. Your primary goal is to provide accurate, up-to-date, and relevant information based on what the user asks and the documents you retrieve.\n\n## Responsibilities\n\n- Answer user queries with a good mix of being comprehensive but still concise\n- Retrieve and synthesize relevant information from the given tools to perform RAG in the 'documents' table, and look up the documents available in your knowledge base in the 'document_metadata' table\n- Present information in an easy-to-understand and professional manner  \n- Clarify misconceptions or misinformation\n\n## Other Key Information and Instructions\n\n- Always start by performing RAG. If RAG doesn't help, then look at the documents that are available to you, find a few that you think would contain the answer, and then analyze those.\n- Always tell the user if you didn't find the answer. Don't make something up just to please them.\n- Keep your language neutral and factual. Do not show bias or opinion  \n\n## Error Handling\n- If the information cannot be found using the provided instructions respond with:  \n  “I’m sorry, I couldn’t find relevant information based on your documents.”\n"
        }
      },
      "id": "4cad65ec-883a-4376-8bfd-157de1eb952e",
      "name": "RAG AI Agent1",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.6,
      "position": [
        1740,
        -80
      ]
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolName": "documents",
        "toolDescription": "Use RAG to look up information in the knowledgebase.",
        "tableName": {
          "__rl": true,
          "value": "documents",
          "mode": "list",
          "cachedResultName": "documents"
        },
        "options": {
          "queryName": "match_documents"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "typeVersion": 1,
      "position": [
        1820,
        80
      ],
      "id": "63813288-8a35-4d7f-a46c-19ce564a4c4a",
      "name": "Document RAG Tool1"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        1940,
        200
      ],
      "id": "0d4c019d-5195-41a3-bfe8-c4b23528375a",
      "name": "Embeddings OpenAI"
    },
    {
      "parameters": {
        "public": true,
        "options": {}
      },
      "id": "c6f5d6ec-05a2-4ec9-808e-1d8f96721166",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        400,
        -80
      ],
      "webhookId": "b86898bf-fb1a-4a3f-9ec8-a79be022d01f"
    },
    {
      "parameters": {
        "content": "## \"Simple\" RAG AI Agent (Still has Contextual Retrieval)",
        "height": 485,
        "width": 736,
        "color": 6
      },
      "id": "f27a68a4-663e-4b40-858b-b1af7def930a",
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1420,
        -160
      ]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const chunks = [];\nconst chunkSize = 400;\nconst chunkOverlap = 0;\nconst text = $json.data.replace(/\\n/, '');\n\nfor (let i=0, j=Math.round(text.length/chunkSize); i<j; i++) {\n  chunks.push(\n    text.substr(\n      Math.max(0,(i * chunkSize)-chunkOverlap),\n      chunkSize\n    )\n  );\n}\n\nreturn { chunks };"
      },
      "id": "f90879ad-c514-4549-8a64-6f6554d5f616",
      "name": "Create Chunks From Doc",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1940,
        480
      ]
    },
    {
      "parameters": {
        "fieldToSplitOut": "chunks",
        "options": {
          "destinationFieldName": "chunk"
        }
      },
      "id": "8b78e4cc-7ea9-4c53-b6b8-c0470be88915",
      "name": "Chunks To List",
      "type": "n8n-nodes-base.splitOut",
      "typeVersion": 1,
      "position": [
        2160,
        620
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=<document> \n{{ $('Extract Document Text').first().json.data }} \n</document>\nHere is the chunk we want to situate within the whole document \n<chunk> \n{{ $json.chunk }}\n</chunk> \nPlease give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else. "
      },
      "id": "f8895e51-c6d3-44fc-9838-22dc09b287c3",
      "name": "Generate Contextual Text",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.4,
      "position": [
        2380,
        480
      ]
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-nano",
          "mode": "list",
          "cachedResultName": "gpt-4.1-nano"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        2460,
        700
      ],
      "id": "e71bc407-a973-4833-a35d-baacd838bd3a",
      "name": "OpenAI Chat Model3"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "069d067c-3534-4939-8ff4-34dee02a9436",
              "name": "chunk",
              "value": "={{ $('Chunks To List').item.json.chunk }}",
              "type": "string"
            },
            {
              "id": "24e01f4f-e156-47e9-a89e-9cbdccda6bd4",
              "name": "text",
              "value": "={{ $('Generate Contextual Text').item.json.text }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "id": "9074395f-d4fa-4921-ac43-edcdbd60b595",
      "name": "Get Values",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        2740,
        640
      ]
    },
    {
      "parameters": {
        "content": "# Dynamous Workshop - Combining RAG Strategies\n\nThis n8n workflow implements a powerful Retrieval-Augmented Generation (RAG) system that integrates three key strategies: Query Expansion, Agentic RAG, and Contextual Retrieval. Together, these approaches create a more accurate and intelligent document retrieval and response generation system.\n\n## Key Components\n\n### 1. Query Expansion\n- Dedicated AI agent expands user queries to be more complete and specific\n- Enhanced queries improve downstream document retrieval quality\n- Agent outputs only questions, which feed into the main RAG pipeline\n\n### 2. Agentic RAG\n- AI agent intelligently selects and uses multiple retrieval tools\n- Can perform iterative searches, analyzing and refining based on initial results\n- Tools include vector similarity search, document metadata lookup, and full document extraction\n- Enables more sophisticated knowledge traversal and connection-making\n\n### 3. Contextual Retrieval\n- Each document chunk is enhanced with contextual information before embedding\n- \"Generate Contextual Text\" node creates context that situates each chunk within the larger document\n- Preserves critical relationships and context that would otherwise be lost in traditional chunking\n- Significantly improves retrieval accuracy by maintaining document coherence\n\n## Technical Implementation\n- Automatic document processing from Google Drive\n- Supabase with pgvector for vector storage and retrieval\n- OpenAI for the LLMs, taking advantage of automatic prompt caching for GPT models to make the contextual retrieval way less expensive.\n\n## Performance Benefits\n- More coherent responses that understand document relationships\n- Reduced hallucinations through better contextual understanding\n- Faster and more relevant answers with less query refinement\n\n## Ideal Use Cases\n- Complex information retrieval across multiple documents\n- Specialized domains requiring deep contextual understanding\n- Research and analysis connecting related concepts\n\n## Why Combine these Strategies?\n\nThis integrated approach demonstrates that combining multiple RAG strategies creates a system more powerful than the sum of its parts, significantly advancing the state-of-the-art in knowledge retrieval and generation.",
        "height": 1360,
        "width": 640,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -300,
        -160
      ],
      "id": "ba923515-c9cf-4469-9cb2-cf995ff30c0f",
      "name": "Sticky Note8"
    }
  ],
  "connections": {
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "RAG AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Download File": {
      "main": [
        [
          {
            "node": "Extract Document Text",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "File Created": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Document Text": {
      "main": [
        [
          {
            "node": "Create Chunks From Doc",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI1": {
      "ai_embedding": [
        [
          {
            "node": "Insert into Supabase Vectorstore",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader": {
      "ai_document": [
        [
          {
            "node": "Insert into Supabase Vectorstore",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Postgres Chat Memory": {
      "ai_memory": [
        [
          {
            "node": "RAG AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Delete Old Doc Rows": {
      "main": [
        [
          {
            "node": "Insert Document Metadata",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set File ID": {
      "main": [
        [
          {
            "node": "Delete Old Doc Rows",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "File Updated": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "List Documents": {
      "ai_tool": [
        [
          {
            "node": "RAG AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Get File Contents": {
      "ai_tool": [
        [
          {
            "node": "RAG AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI2": {
      "ai_embedding": [
        [
          {
            "node": "Document RAG Tool",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Items": {
      "main": [
        [],
        [
          {
            "node": "Set File ID",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Insert into Supabase Vectorstore": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Insert Document Metadata": {
      "main": [
        [
          {
            "node": "Download File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Recursive Character Text Splitter": {
      "ai_textSplitter": [
        [
          {
            "node": "Default Data Loader",
            "type": "ai_textSplitter",
            "index": 0
          }
        ]
      ]
    },
    "Document RAG Tool": {
      "ai_tool": [
        [
          {
            "node": "RAG AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Query Expansion",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Query Expansion": {
      "main": [
        [
          {
            "node": "RAG AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "RAG AI Agent1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Postgres Chat Memory1": {
      "ai_memory": [
        [
          {
            "node": "RAG AI Agent1",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Document RAG Tool1": {
      "ai_tool": [
        [
          {
            "node": "RAG AI Agent1",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI": {
      "ai_embedding": [
        [
          {
            "node": "Document RAG Tool1",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "Query Expansion",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chunks To List": {
      "main": [
        [
          {
            "node": "Generate Contextual Text",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Chunks From Doc": {
      "main": [
        [
          {
            "node": "Chunks To List",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Generate Contextual Text",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Generate Contextual Text": {
      "main": [
        [
          {
            "node": "Get Values",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Values": {
      "main": [
        [
          {
            "node": "Insert into Supabase Vectorstore",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "versionId": "a1b2e469-0d5e-49e2-ad46-bbcacc2bdbc1",
  "triggerCount": 0,
  "tags": []
}